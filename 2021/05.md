---
presentation:
  transition: "none"
  enableSpeakerNotes: true
  margin: 0
---

@import "../common/css/font-awesome-4.7.0/css/font-awesome.css"
@import "../common/css/zhangt-solarized.css"
@import "css/GNN.css"

<!-- slide data-notes="" -->
<div class="header"><img class="hust"></div>

<div class="bottom15"></div>

# 图神经网络导论

<hr class="width50">

## 卷积神经网络

<div class="bottom5"></div>

### 计算机科学与技术学院 &nbsp; &nbsp; 张腾

<br>

#### tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 大纲

@import "../dot/outline-cnn.dot"

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="" -->

GNN-HEADER 局部连接

设样本是 100 × 100 的图片，对全连接网络，第一个隐藏层每个神经元都对应 10000 个权重参数，随着神经元数量增多，参数规模急剧增加

- 训练效率非常低
- 很容易出现过拟合

@import "../dot/dense-vs-cnn.dot" {.center}

局部连接：限制神经元的输入权重个数，降低参数规模和模型复杂度

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 权重共享

<img src="../tikz/convolution1d.svg" class="center width75 top4 bottom4">

<div class="center">

$$
\begin{align*}
    a_1 & = x_1 \times w_1 + x_2 \times w_2 + x_3 \times w_3 \\
    a_2 & = x_2 \times w_1 + x_3 \times w_2 + x_4 \times w_3 \\
    a_3 & = x_3 \times w_1 + x_4 \times w_2 + x_5 \times w_3 \\
    a_4 & = x_4 \times w_1 + x_5 \times w_2 + x_6 \times w_3
\end{align*}
$$

</div>

<div class="bottom4"></div>

### 卷积神经网络：局部连接，权值共享

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="这页是在讲为啥叫卷积" -->

GNN-HEADER 一维卷积

$$
\begin{align*}
    (f \otimes g) [n] = \sum_{m = -\infty}^\infty f[m] \cdot g[n-m]
\end{align*}
$$

<img src="../tikz/convolution1d.svg" class="center width75 top3 bottom4">

取$f[i] = x_i$，$g[-2] = w_3$，$g[-1] = w_2$，$g[0] = w_1$，其余为零，则有

$$
\begin{align*}
    a_n = x_n w_1 + x_{n+1} w_2 + x_{n+2} w_3 = \sum_{m=n}^{n+2} f[m] \cdot g[n-m] = (f \otimes g) [n]
\end{align*}
$$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 二维卷积

针对输入是矩阵的情形

<img src="../tikz/convolution2d.svg" class="center width75 top3 bottom4">

参与卷积的深色区域称为对应输出神经元的感受野 (receptive field)

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="" -->

GNN-HEADER 图像滤波

平滑去噪

<div class="multi_column top6 left6" style="height:280px">
    <img src="../common/img/tj.jpg" class="height100" >
    <div style="display:flex;align-items:center;height:100%">
        <p class="left2">
            $\otimes ~ \begin{bmatrix}
                \frac{1}{9} & \frac{1}{9} & \frac{1}{9} \\ \frac{1}{9} & \frac{1}{9} & \frac{1}{9} \\ \frac{1}{9} & \frac{1}{9} & \frac{1}{9}
            \end{bmatrix} ~ =$ 
        </p>
    </div>
    <img src="../common/img/tj1.jpg" class="left-2 height100">
</div>

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 图像卷积

边缘提取

<div class="multi_column top6 left6" style="height:280px">
    <img src="../common/img/tj.jpg" class="height100" >
    <div style="display:flex;align-items:center;height:100%">
        <p class="left2">
            $\otimes ~ \begin{bmatrix}
                0 & 1 & 1 \\ -1 & 0 & 1 \\ -1 & -1 & 0
            \end{bmatrix} ~ = $ 
        </p>
    </div>
    <img src="../common/img/tj3.jpg" class="left-2 height100">
</div>

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 图像卷积

边缘提取

<div class="multi_column top6 left6" style="height:280px">
    <img src="../common/img/tj.jpg" class="height100" >
    <div style="display:flex;align-items:center;height:100%">
        <p class="left2">
            $\otimes ~ \begin{bmatrix}
                0 & 1 & 0 \\ 1 & -4 & 1 \\ 0 & 1 & 0
            \end{bmatrix} ~ = $
        </p>
    </div>
    <img src="../common/img/tj2.jpg" class="left-2 height100">
</div>

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 拉普拉斯算子

偏导数

$$
\begin{align*}
    \frac{\partial f}{\partial x} = \lim_{u \rightarrow 0} \frac{f(x+u, y) - f(x-u, y)}{2 u} \overset{u \leftarrow 0.5}{\approx} f(x+\frac{1}{2}, y) - f(x-\frac{1}{2}, y)
\end{align*}
$$

于是

$$
\begin{align*}
    \Delta & f = \div (\grad f) = \left[ \frac{\partial}{\partial x}, \frac{\partial}{\partial y} \right] \cdot \left[ \frac{\partial f}{\partial x}; \frac{\partial f}{\partial y} \right] = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} \\
    & = \frac{\partial f(x+\frac{1}{2}, y)}{\partial x} - \frac{\partial f(x-\frac{1}{2}, y)}{\partial x} + \frac{\partial f(x, y+\frac{1}{2})}{\partial y} - \frac{\partial f(x, y-\frac{1}{2})}{\partial y} \\
    & \approx (f(x+1, y) - f(x, y)) - (f(x, y) - f(x-1, y)) \\
    & \qquad \qquad \qquad + (f(x, y+1) - f(x, y)) - (f(x, y) - f(x, y-1)) \\
    & = f(x+1, y) + f(x-1, y) + f(x, y-1) + f(x, y+1) - 4 f(x, y)
\end{align*}
$$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="" -->

GNN-HEADER 卷积超参数

引入参数可以更灵活地进行特征抽取

- 大小$c$：滤波器的长度
- 步长$s$：滤波器滑动的间隔
- 补零$p$：输入神经元两端各补零的个数

<br>

$s=2$：

<img src="../tikz/convolution1d-stepsize.svg" class="center width75 top3 bottom4">

若输入神经元个数为$n$，则卷积层神经元个数为$(n - c) / s + 1$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 卷积超参数

引入参数可以更灵活地进行特征抽取

- 大小$c$：滤波器的长度
- 步长$s$：滤波器滑动的间隔
- 补零$p$：输入神经元两端各补零的个数

<br>

$p=1$：

<img src="../tikz/convolution1d-padding.svg" class="center width75 top3 bottom4">

若输入神经元个数为$n$，则卷积层神经元个数为$(n - c + 2p) / s + 1$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 卷积超参数

引入参数可以更灵活地进行特征抽取

- 大小$c$：滤波器的长度
- 步长$s$：滤波器滑动的间隔
- 补零$p$：输入神经元两端各补零的个数

<br>

若输入神经元个数为$n$，则卷积层神经元个数为$(n - c + 2p) / s + 1$

<br>

常用的卷积有如下三类：

- 窄卷积：步长$s = 1$，两端不补零$p = 0$，卷积后输出长度为$n − c + 1$
- 宽卷积：步长$s = 1$，两端补零$p = c - 1$，卷积后输出长度为$n + c - 1$
- 等宽卷积：步长$s = 1$，两端补零$p = (c − 1) / 2$，卷积后输出长度$n$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="" -->

GNN-HEADER 参数求导

设$\Zv = \Av \otimes \Wv + b$，$\Av \in \Rbb^{U \times V}$，$\Wv \in \Rbb^{u \times v}$，$\Zv \in \Rbb^{(U-u+1) \times (V-v+1)}$

$$
\begin{align*}
    z_{ij} = \sum_{u,v} w_{uv} a_{i+u-1, j+v-1} + b
\end{align*}
$$

记$\deltav^\top = \partial \Lcal(\yv, \hat{\yv}) / \partial \Zv$为误差项，由链式法则有

$$
\begin{align*}
    \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial b} & = \sum_{i,j} \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial z_{ij}} \frac{\partial z_{ij}}{\partial b} = \sum_{i,j} [\deltav]_{ij} \\
    \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial w_{uv}} & = \sum_{i,j} \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial z_{ij}} \frac{\partial z_{ij}}{\partial w_{uv}} = \sum_{i,j} a_{i+u-1, j+v-1} [\deltav]_{ij} \\
    & \Longrightarrow \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial \Wv} = \Av \otimes \deltav
\end{align*}
$$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide vertical=true data-notes="" -->

GNN-HEADER 参数求导

设$\Zv = \Av \otimes \Wv + b$，$\Av \in \Rbb^{U \times V}$，$\Wv \in \Rbb^{u \times v}$，$\Zv \in \Rbb^{(U-u+1) \times (V-v+1)}$

$$
\begin{align*}
    z_{ij} = \sum_{u,v} w_{uv} a_{i+u-1, j+v-1} + b
\end{align*}
$$

记$\deltav^\top = \partial \Lcal(\yv, \hat{\yv}) / \partial \Zv$为误差项，由链式法则有

$$
\begin{align*}
    \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial a_{st}} = \sum_{i,j} \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial z_{ij}} \frac{\partial z_{ij}}{\partial a_{st}} = \sum_{i,j} w_{s-i+1,t-j+1} [\deltav]_{ij}
\end{align*}
$$

当$s-i+1 \not \in [u]$或者$t-j+1 \not \in [v]$时，令$w_{s-i+1,t-j+1} = 0$，相当于对$\Wv$进行了$p = (U - u, V - v)$的零填充，记$\widetilde{\otimes}$为<span class="blue">宽卷积</span>

$$
\begin{align*}
    \frac{\partial \Lcal (\yv, \hat{\yv})}{\partial \Av} = \rot(\Wv) \widetilde{\otimes} \deltav
\end{align*}
$$

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn

<!-- slide data-notes="" -->

GNN-HEADER 池化

池化 (pooling) 层也叫子采样 (subsampling) 层

<br>

- 最大池化 (maximum pooling)：取一个区域内所有神经元的最大值，<span class="blue">拥有一定的平移不变性</span>

<img src="../tikz/pooling-max.svg" style="margin:2rem" height=200px>

- 平均池化 (mean pooling)：取一个区域内所有神经元的平均值

<br>

作用：将区域下采样为一个值实现特征选择，进一步减少网络参数，降低模型复杂度

GNN-FOOTER 图神经网络导论 卷积神经网络 tengzhang@hust.edu.cn
