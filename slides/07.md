---
presentation:
    transition: "none"
    enableSpeakerNotes: true
    margin: 0
---

@import "../common/css/zhangt-style.css"
@import "../common/css/font-awesome-4.7.0/css/font-awesome.css"

<!-- slide data-notes="" -->
<div id="logo">
    <img src="../common/img/xiaohui.png" style="" height=120px>
    <img src="../common/img/bdts.png" style="margin-top:0.5rem" height=100px>
</div>

<div>
    <h1 style="width: 50%">
        图神经网络导论</br> 
        <span style="font-size: 0.6em">谱图理论</span>
    </h1>
    <h2>张腾</h2>
    <h3>tengzhang@hust.edu.cn</h3>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">Laplace矩阵</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

定义：$\Lv = \Dv - \Av$

-   $\Lv$半正定：对$\forall \xv \in \Rbb^{|\Vcal|}$

<div>
    $$
        \begin{align*}
            \xv^\top & \Lv \xv = \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Dv]_{uv} [\xv]_v - \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Av]_{uv} [\xv]_v \\
                        & = \sum_{u \in \Vcal} [\xv]_u^2 d_u - \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Av]_{uv} [\xv]_v                          \\
                        & = \frac{1}{2} \left( \sum_{u \in \Vcal} \sum_{v \in \Vcal} ([\xv]_u^2 [\Av]_{uv} + [\xv]_v^2 [\Av]_{vu}) - 2 \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Av]_{uv} [\xv]_v \right) \\
                        & = \frac{1}{2} \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\Av]_{uv} ([\xv]_u - [\xv]_v)^2 \geq 0
        \end{align*}
    $$
</div>

-   $\Lv \ev = \Dv \ev - \Av \ev = \zerov = 0 \ev$，故$0 = \lambda_{|\Vcal|} \leq \cdots \leq \lambda_1$

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">Laplace矩阵</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

<div>
    $$
        \begin{align*}
            \xv^\top \Lv \xv = \frac{1}{2} \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\Av]_{uv} ([\xv]_u - [\xv]_v)^2 = \frac{1}{2} \sum_{(u,v) \in \Ecal} ([\xv]_u - [\xv]_v)^2
        \end{align*}
    $$
</div>

Laplace 矩阵最小特征值$0$的几何重数等于图的连通分支数

证明：设$\xv$是$0$对应的任一特征向量，于是有$\xv^\top \Lv \xv = \xv^\top 0 \xv = 0$，从而$(u,v) \in \Ecal \Rightarrow [\xv]_u = [\xv]_v$，进一步$\xv$在任一连通分支上的值相等

-   全连通图只有一个连通分支，此时$\xv = c \ev$，即$0$的几何重数为$1$
-   设图有$K$个连通分支$\Vcal = \Vcal_1 \times \cdots \times \Vcal_K$，将点按连通分支排序，则邻接矩阵为分块对角阵$\Av = \diag\{ \Av_1, \ldots, \Av_K \}$，又$\Dv$是对角阵，故 Laplace 矩阵也为分块对角阵$\Lv = \diag\{ \Lv_1, \ldots, \Lv_K \}$，其中$\Lv_i$是第$i$个连通分支的 Laplace 矩阵，其最小特征值$0$对应的特征向量$\ev \in \Rbb^{|\Vcal_i|}$，将其补零到$|\Vcal|$维得到$\ev_{\Vcal_i}$，显然$\ev_{\Vcal_1}, \ldots, \ev_{\Vcal_K}$是$\Lv$的对应于$0$的$K$个线性无关的特征向量

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">归一化Laplace矩阵</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

对称 Laplace 矩阵：$\Lv_{\text{sym}} = \Dv^{-1/2} \Lv \Dv^{-1/2} = \Iv - \Dv^{-1/2} \Av \Dv^{-1/2}$

随机游走 Laplace 矩阵：$\Lv_{\text{rm}} = \Dv^{-1} \Lv = \Iv - \Dv^{-1} \Av$，第二项就是随机游走的转移矩阵，由此得名

<div>
    $$
        \begin{align*}
            \xv^\top \Lv_{\text{sym}} \xv & = \sum_{u \in \Vcal} [\xv]_u^2 - \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Av]_{uv} [\xv]_v / \sqrt{d_u d_v} \\
                        & = \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u^2 [\Av]_{uv} / d_u - \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\xv]_u [\Av]_{uv} [\xv]_v / \sqrt{d_u d_v}                          \\
                        & = \frac{1}{2} \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\Av]_{vu} \left( [\xv]_u^2 / d_u + [\xv]_v^2 / d_v - 2 [\xv]_u [\xv]_v / \sqrt{d_u d_v} \right) \\
                        & = \frac{1}{2} \sum_{u \in \Vcal} \sum_{v \in \Vcal} [\Av]_{uv} \left( \frac{[\xv]_u}{\sqrt{d_u}} - \frac{[\xv]_v}{\sqrt{d_v}} \right)^2
        \end{align*}
    $$
</div>

即$\Lv_{\text{sym}}$半正定，有$|\Vcal|$个非负特征值：$0 \leq \lambda_{|\Vcal|} \leq \cdots \leq \lambda_1$

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">归一化Laplace矩阵</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

对称 Laplace 矩阵：$\Lv_{\text{sym}} = \Dv^{-1/2} \Lv \Dv^{-1/2} = \Iv - \Dv^{-1/2} \Av \Dv^{-1/2}$

随机游走 Laplace 矩阵：$\Lv_{\text{rm}} = \Dv^{-1} \Lv = \Iv - \Dv^{-1} \Av$

</br>

$(\lambda, \vv)$是$\Lv_{\text{rm}}$的特征值/向量当且仅当$\Lv \vv = \lambda \Dv \vv$

<div>
    $$
        \begin{align*}
            \lambda \Dv \vv = \Dv \lambda \vv = \Dv \Lv_{\text{rm}} \vv = \Dv \Dv^{-1} \Lv \vv = \Lv \vv
        \end{align*}
    $$
</div>

</br>

$(\lambda, \vv)$是$\Lv_{\text{rm}}$的特征值/向量当且仅当$(\lambda, \Dv^{1/2} \vv)$是$\Lv_{\text{sym}}$的特征值/向量

<div>
    $$
        \begin{align*}
            \lambda \vv & = \Lv_{\text{rm}} \vv = \Dv^{-1} \Lv \vv = \Dv^{-1/2} \Dv^{-1/2} \Lv \Dv^{-1/2} \Dv^{1/2} \vv \\
            & = \Dv^{-1/2} \Lv_{\text{sym}} \Dv^{1/2} \vv \\
            & \Longleftrightarrow \lambda \Dv^{1/2} \vv = \Lv_{\text{sym}} \Dv^{1/2} \vv
        \end{align*}
    $$
</div>

故$\Lv_{\text{rm}}$也半正定，有$|\Vcal|$个非负特征值：$0 \leq \lambda_{|\Vcal|} \leq \cdots \leq \lambda_1$

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">归一化Laplace矩阵</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

对称 Laplace 矩阵：$\Lv_{\text{sym}} = \Dv^{-1/2} \Lv \Dv^{-1/2} = \Iv - \Dv^{-1/2} \Av \Dv^{-1/2}$

随机游走 Laplace 矩阵：$\Lv_{\text{rm}} = \Dv^{-1} \Lv = \Iv - \Dv^{-1} \Av$

</br>

$(0, \ev)$是$\Lv_{\text{rm}}$的特征值/向量，$(0, \Dv^{1/2} \ev)$是$\Lv_{\text{sym}}$的特征值/向量

$$
    \begin{align*}
        \Lv_{\text{rm}} \ev & = \Dv^{-1} \Lv \ev = \Dv^{-1} 0 \ev = \zerov = 0 \ev \\
        \Lv_{\text{sym}} \Dv^{1/2} \ev & = \Dv^{-1/2} \Lv \Dv^{-1/2} \Dv^{1/2} \ev = \Dv^{-1/2} \Lv \ev = \Dv^{-1/2} 0 \ev = \zerov
    \end{align*}
$$

</br>

$\Lv_{\text{sym}}$和$\Lv_{\text{rm}}$最小特征值$0$的几何重数等于图的连通分支数

证明：$\Lv_{\text{sym}}$和$\Lv_{\text{rm}}$与$\Lv$有相同的分块对角形式

-   $\Lv_{\text{rm}}$对应于$0$的特征向量由$\ev_{\Vcal_1}, \ldots, \ev_{\Vcal_K}$张成
-   $\Lv_{\text{sym}}$对应于$0$的特征向量由$\Dv^{1/2} \ev_{\Vcal_1}, \ldots, \Dv^{1/2} \ev_{\Vcal_K}$张成

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">图割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

设$\Vcal = \Vcal_1 \times \cdots \times \Vcal_K$，定义图割为划分点集时需破坏的边数：

<div>
    $$
        \begin{align*}
            \cut (\Vcal_1, \ldots, \Vcal_K) = \frac{1}{2} \sum_{k \in [K]} | (u,v) \in \Ecal: u \in \Vcal_k, v \in \overline{\Vcal}_k |
        \end{align*}
    $$
</div>

一个好的划分(对点做聚类)应该尽可能少的破坏边

问题：可能只划分出一个点

</br>

比例割和归一化割

<div>
    $$
        \begin{align*}
            \rcut (\{ \Vcal_k \}_{k \in [K]}) & = \sum_{k \in [K]} \frac{\cut (\Vcal_k, \overline{\Vcal}_k)}{|\Vcal_k|} \\
            \ncut (\{ \Vcal_k \}_{k \in [K]}) & = \sum_{k \in [K]} \frac{\cut (\Vcal_k, \overline{\Vcal}_k)}{\sum_{u \in \Vcal_k} d_u}
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 比例割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

设$K=2$，即将点集一分为二，则优化问题为$\min_{\Acal \subseteq \Vcal} ~ \rcut (\Acal, \overline{\Acal})$

定义指示向量$\fv \in \Rbb^{|\Vcal|}$

<div>
    $$
        \begin{align*}
            [\fv]_v = \begin{cases}
                \sqrt{|\overline{\Acal}| / |\Acal|} & 若~v \in \Acal \\
                - \sqrt{|\Acal| / |\overline{\Acal}|} & 若~v \not \in \Acal
            \end{cases}
        \end{align*}
    $$
</div>

易知

<div>
    $$
        \begin{align*}
            & \fv^\top \Lv \fv = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} ([\fv]_u - [\fv]_v)^2 + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} ([\fv]_u - [\fv]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} \left( \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} + \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} \right)^2 + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} \left( \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} + \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} \right)^2
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 比例割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

<div>
    $$
        \begin{align*}
            & \fv^\top \Lv \fv = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} ([\fv]_u - [\fv]_v)^2 + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} ([\fv]_u - [\fv]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} \left( \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} + \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} \right)^2 + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} \left( \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} + \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} \right)^2 \\
            & = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} \left( \frac{|\overline{\Acal}|}{|\Acal|} + \frac{|\Acal|}{|\overline{\Acal}|} + 2 \right) + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} \left( \frac{|\overline{\Acal}|}{|\Acal|} + \frac{|\Acal|}{|\overline{\Acal}|} + 2 \right) \\
            & = \cut (\Acal, \overline{\Acal}) \left( \frac{|\overline{\Acal}| + |\Acal|}{|\Acal|} + \frac{|\Acal| + |\overline{\Acal}|}{|\overline{\Acal}|} \right) \\
            & = |\Vcal| \rcut (\Acal, \overline{\Acal})
        \end{align*}
    $$
</div>

</br>

这表明目标函数可以通过 Laplace 矩阵表示

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 比例割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

$\fv$满足

<div>
    $$
        \begin{align*}
            \fv^\top \ev & = \sum_{u \in \Acal} \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} - \sum_{u \not \in \Acal} \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} = |\Acal| \sqrt{\frac{|\overline{\Acal}|}{|\Acal|}} - |\overline{\Acal}| \sqrt{\frac{|\Acal|}{|\overline{\Acal}|}} = 0 \\
            \fv^\top \fv & = \sum_{u \in \Vcal} [\fv]_u^2 = \sum_{u \in \Acal} [\fv]_u^2 + \sum_{u \not \in \Acal} [\fv]_u^2 = |\Acal| \frac{|\overline{\Acal}|}{|\Acal|} + |\overline{\Acal}| \frac{|\Acal|}{|\overline{\Acal}|} = |\Vcal|
        \end{align*}
    $$
</div>

综上优化问题为

<div>
    $$
        \begin{align*}
            \min_{\Acal \subseteq \Vcal} ~ \fv^\top \Lv \fv \quad \st & ~ [\fv]_v = \begin{cases}
                \sqrt{|\overline{\Acal}| / |\Acal|} & 若~v \in \Acal \\
                - \sqrt{|\Acal| / |\overline{\Acal}|} & 若~v \not \in \Acal
            \end{cases} \\
            & ~ \fv^\top \ev = 0, ~ \fv^\top \fv = |\Vcal|
        \end{align*}
    $$
</div>

难点：离散优化，NP-hard

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 比例割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

去掉离散约束，问题放松为

<div>
    $$
        \begin{align*}
            \min_{\fv} ~ \fv^\top \Lv \fv & \quad \st ~ \fv^\top \ev = 0, ~ \fv^\top \fv = |\Vcal|
        \end{align*}
    $$
</div>

设$\Lv$的特征值：$0 = \lambda_{|\Vcal|} \leq \cdots \leq \lambda_1$，对应特征向量：$\ev / \|\ev\| = \vv_{|\Vcal|}, \ldots, \vv_1$

设$\fv = \alpha_1 \vv_1 + \cdots + \alpha_{|\Vcal|} \vv_{|\Vcal|}$，第一个约束$\fv^\top \ev = \alpha_{|\Vcal|} \|\ev\| = 0 \Rightarrow \alpha_{|\Vcal|} = 0$，第二个约束$\fv^\top \fv = \alpha_1^2 + \cdots + \alpha_{|\Vcal|}^2 = |\Vcal|$

<div>
    $$
        \begin{align*}
            \fv^\top \Lv \fv & = (\alpha_1 \vv_1 + \cdots + \alpha_{|\Vcal|} \vv_{|\Vcal|})^\top (\alpha_1 \lambda_1 \vv_1 + \cdots + \alpha_{|\Vcal| } \lambda_{|\Vcal|} \vv_{|\Vcal|}) \\
            & = \alpha_1^2 \lambda_1 + \cdots + \alpha_{|\Vcal|}^2 \lambda_{|\Vcal|} = \alpha_1^2 \lambda_1 + \cdots + \alpha_{|\Vcal|-1}^2 \lambda_{|\Vcal|-1} \\
            & \geq \alpha_1^2 \lambda_{|\Vcal|-1} + \cdots + \alpha_{|\Vcal|-1}^2 \lambda_{|\Vcal|-1} = |\Vcal| \lambda_{|\Vcal|-1}
        \end{align*}
    $$
</div>

取等号条件为$\fv$正比于倒数第二小特征值对应的特征向量

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 比例割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

优化问题

<div>
    $$
        \begin{align*}
            \min_{\fv \in\Rbb^{|\Vcal|}} ~ \fv^\top \Lv \fv & \quad \st ~ \fv^\top \ev = 0, ~ \fv^\top \fv = |\Vcal|
        \end{align*}
    $$
</div>

的最优解为$\fv^\star = \sqrt{|\Vcal|} \vv_{|\Vcal|-1}$

</br>

反推划分

-   $v \in \Acal$当且仅当$[\fv]_v \geq 0$
-   将$\{ [\fv]_1, \ldots, [\fv]_{|\Vcal|} \}$看成$\Rbb$上的$|\Vcal|$个点，聚成两簇$\Ccal$、$\overline{\Ccal}$，$v \in \Acal$当且仅当$[\fv]_v \in \Ccal$

</br>

后者就是$K = 2$的未归一化谱聚类

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 比例割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

设$K > 2$，则优化问题为$\min_{\Vcal_1, \ldots, \Vcal_K} ~ \rcut (\Vcal_1, \ldots, \Vcal_K)$

定义$K$个指示向量$\hv_k \in \Rbb^{|\Vcal|}$

<div>
    $$
        \begin{align*}
            [\hv_k]_v = \begin{cases}
                1 / \sqrt{|\Vcal_k|} & 若~v \in \Vcal_k \\
                0 & 若~v \not \in \Vcal_k
            \end{cases}
        \end{align*}
    $$
</div>

易知

<div>
    $$
        \begin{align*}
            \hv_k^\top \Lv \hv_k & = \frac{1}{2} \sum_{(u,v) \in \Ecal} ([\hv_k]_u - [\hv_k]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Vcal_k, v \not \in \Vcal_k} ([\hv_k]_u - [\hv_k]_v)^2 + \frac{1}{2} \sum_{u \not \in \Vcal_k, v \in \Vcal_k} ([\hv_k]_u - [\hv_k]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Vcal_k, v \not \in \Vcal_k} \frac{1}{|\Vcal_k|} + \frac{1}{2} \sum_{u \not \in \Vcal_k, v \in \Vcal_k} \frac{1}{|\Vcal_k|} = \frac{\cut (\Vcal_k, \overline{\Vcal}_k)}{|\Vcal_k|} 
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 比例割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

于是

<div>
    $$
        \begin{align*}
            \rcut (\Vcal_1, \ldots, \Vcal_K) & = \sum_{k \in [K]} \frac{\cut(\Vcal_k, \overline{\Vcal_k})}{|\Vcal_k|} = \sum_{k \in [K]} \hv_k^\top \Lv \hv_k \\
            & = \sum_{k \in [K]} [\Hv^\top \Lv \Hv]_{kk} = \tr (\Hv^\top \Lv \Hv)
        \end{align*}
    $$
</div>

其中$\Hv = [\hv_1, \ldots, \hv_K]$，注意$\Hv$的列相互正交且$\Hv^\top \Hv = \Iv$

</br>

综上优化问题为

<div>
    $$
        \begin{align*}
            \min_{\Vcal_1, \ldots, \Vcal_K} ~ \tr (\Hv^\top \Lv \Hv) \quad \st ~ \Hv^\top \Hv = \Iv, ~ [\hv_k]_v = \begin{cases}
                1 / \sqrt{|\Vcal_k|} & 若~v \in \Vcal_k \\
                0 & 若~v \not \in \Vcal_k
            \end{cases} \\
        \end{align*}
    $$
</div>

难点：离散优化，NP-hard

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 比例割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

去掉离散约束，问题放松为

<div>
    $$
        \begin{align*}
            \min_{\Hv \in \Rbb^{|\Vcal| \times K}} ~ \tr (\Hv^\top \Lv \Hv) \quad \st ~ \Hv^\top \Hv = \Iv
        \end{align*}
    $$
</div>

设$\Lv = \sum_{i \in [|\Vcal|]} \lambda_i \vv_i \vv_i^\top = \Vv \Lambdav \Vv^\top$，记$\Hv = \Vv \Qv$

-   $\Hv^\top \Lv \Hv = \Qv^\top \Vv^\top \Vv \Lambdav \Vv^\top \Vv \Qv = \Qv^\top \Lambdav \Qv$
-   $\Hv^\top \Hv = \Qv^\top \Vv^\top \Vv \Qv = \Qv^\top \Qv$

将$\Qv$扩充为正交矩阵$\widetilde{\Qv} = [\Qv, \overline{\Qv}]$，考虑问题

<div>
    $$
        \begin{align*}
            \min_{\widetilde{\Qv} \in \Rbb^{|\Vcal| \times |\Vcal|}} & ~ \tr (\widetilde{\Qv}^\top \Lambdav \widetilde{\Qv}) = \tr (\Qv^\top \Lambdav \Qv) + \tr (\overline{\Qv}^\top \Lambdav \overline{\Qv}) \\
            \st & ~ \widetilde{\Qv}^\top \widetilde{\Qv} = \begin{bmatrix} \Qv^\top \Qv \\ & \overline{\Qv}^\top \overline{\Qv} \end{bmatrix} = \Iv
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 比例割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

$\widetilde{\Qv} = [\Qv, \overline{\Qv}]$，考虑问题

<div>
    $$
        \begin{align*}
            \min_{\widetilde{\Qv} \in \Rbb^{|\Vcal| \times |\Vcal|}} ~ \tr (\widetilde{\Qv}^\top \Lambdav \widetilde{\Qv}) \quad \st ~ \widetilde{\Qv}^\top \widetilde{\Qv} = \Iv
        \end{align*}
    $$
</div>

-   $\tr (\widetilde{\Qv}^\top \Lambdav \widetilde{\Qv}) = \sum_i \qv_i^\top \Lambdav \qv_i = \sum_{i,j} \lambda_j \widetilde{q}_{ij}^2$
-   $\Sv = \widetilde{\Qv} \circ \widetilde{\Qv} = (\widetilde{q}_{ij}^2)$是一个双随机矩阵，行和列和均为$1$

<div>
    $$
        \begin{align*}
            \min_{\widetilde{\Qv}^\top \widetilde{\Qv} = \Iv} \tr (\widetilde{\Qv}^\top \Lambdav \widetilde{\Qv}) = \min_{\widetilde{\Qv}^\top \widetilde{\Qv} = \Iv} \sum_{i,j} \lambda_j \widetilde{q}_{ij}^2 \geq \min_{\Sv \in \Scal} \sum_{i,j} \lambda_j s_{ij}
        \end{align*}
    $$
</div>

其中$\Scal$是双随机矩阵集合，上式最右端是线性规划，所以最优解为可行域$\Scal$的极点，由 Birkhoff–von Neumann 定理知$\Scal$的极点是置换矩阵，而置换矩阵是正交矩阵，因此上式不等号可以取等号，原问题只取$\widetilde{\Qv}$的前$K$列，故原问题最优解是最小的$K$个特征值对应的特征向量

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 比例割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

问题

<div>
    $$
        \begin{align*}
            \min_{\Hv \in \Rbb^{|\Vcal| \times K}} ~ \tr (\Hv^\top \Lv \Hv) \quad \st ~ \Hv^\top \Hv = \Iv
        \end{align*}
    $$
</div>

的最优解为$\Lv$最小的$K$个特征值对应的特征向量，不妨记为$\vv_1, \ldots, \vv_K$

</br>

反推划分：将$\Vv= [\vv_1, \ldots, \vv_K] \in \Rbb^{|\Vcal| \times K}$看作$|\Vcal|$个$K$维点，将其聚成$K$簇$\Ccal_1, \ldots, \Ccal_K$，$v \in \Vcal_k$当且仅当$[\Vv]_v \in \Ccal_k$

</br>

这就是一般形式的未归一化谱聚类

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

优化问题为$\min_{\Acal \subseteq \Vcal} ~ \ncut (\Acal, \overline{\Acal})$

定义指示向量$\fv \in \Rbb^{|\Vcal|}$

<div>
    $$
        \begin{align*}
            [\fv]_v = \begin{cases}
                \sqrt{ \vol(\overline{\Acal}) / \vol(\Acal) } & 若~v \in \Acal \\
                - \sqrt{ \vol(\Acal) / \vol(\overline{\Acal}) } & 若~v \not \in \Acal
            \end{cases}
        \end{align*}
    $$
</div>

易知

<div>
    $$
        \begin{align*}
            \fv^\top \Lv \fv & = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} \left( \sqrt{\frac{\vol(\overline{\Acal})}{\vol(\Acal)}} + \sqrt{\frac{\vol(\Acal)}{\vol(\overline{\Acal})}} \right)^2  \\
            & \qquad + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} \left( \sqrt{\frac{\vol(\Acal)}{\vol(\overline{\Acal})}} + \sqrt{\frac{\vol(\overline{\Acal})}{\vol(\Acal)}} \right)^2
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

<div>
    $$
        \begin{align*}
            \fv^\top \Lv \fv & = \frac{1}{2} \sum_{u \in \Acal, v \not \in \Acal} \left( \frac{\vol(\overline{\Acal})}{\vol(\Acal)} + \frac{\vol(\Acal)}{\vol(\overline{\Acal})} + 2 \right)  \\
            & \qquad + \frac{1}{2} \sum_{u \not \in \Acal, v \in \Acal} \left( \frac{\vol(\Acal)}{\vol(\overline{\Acal})} + \frac{\vol(\overline{\Acal})}{\vol(\Acal)} + 2 \right) \\
            & = \cut (\Acal, \overline{\Acal}) \left( \frac{\vol(\Acal) + \vol(\overline{\Acal})}{\vol(\overline{\Acal})} + \frac{\vol(\overline{\Acal}) + \vol(\Acal)}{\vol(\Acal)}\right) \\
            & = \vol(\Vcal) \cut (\Acal, \overline{\Acal}) \left( \frac{1}{\vol(\overline{\Acal})} + \frac{1}{\vol(\Acal)}\right) \\
            & = \vol(\Vcal) \ncut (\Acal, \overline{\Acal})
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

<div>
    $$
        \begin{align*}
            (D \fv)^\top \ev & = \sum_{u \in \Acal} d_u \sqrt{\frac{\vol(\overline{\Acal})}{\vol(\Acal)}} - \sum_{u \not \in \Acal} d_u \sqrt{\frac{\vol(\Acal)}{\vol(\overline{\Acal})}} \\
            & = \vol(\Acal) \sqrt{\frac{\vol(\overline{\Acal})}{\vol(\Acal)}} - \vol(\overline{\Acal}) \sqrt{\frac{\vol(\Acal)}{\vol(\overline{\Acal})}} \\
            & = 0 \\
            \fv^\top \Dv \fv & = \sum_{u \in \Acal} d_u [\fv]_u^2 + \sum_{u \not \in \Acal} d_u [\fv]_u^2 = \sum_{u \in \Acal} d_u \frac{\vol(\overline{\Acal})}{\vol(\Acal)} + \sum_{u \not \in \Acal} d_u \frac{\vol(\Acal)}{\vol(\overline{\Acal})} \\
            & = \vol(\Acal) \frac{\vol(\overline{\Acal})}{\vol(\Acal)} + \vol(\overline{\Acal}) \frac{\vol(\Acal)}{\vol(\overline{\Acal})} \\
            & = \vol(\Vcal)
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

综上优化问题为

<div>
    $$
        \begin{align*}
            \min_{\Acal \subseteq \Vcal} ~ \fv^\top \Lv \fv \quad \st & ~ [\fv]_v = \begin{cases}
                \sqrt{ \vol(\overline{\Acal}) / \vol(\Acal) } & 若~v \in \Acal \\
                - \sqrt{ \vol(\Acal) / \vol(\overline{\Acal}) } & 若~v \not \in \Acal
            \end{cases}~~~~~~ \\
            & ~ (D \fv)^\top \ev = 0, ~ \fv^\top \Dv \fv = \vol(\Vcal)
        \end{align*}
    $$
</div>

</br>

难点：离散优化，NP-hard

</br>

将问题放松为

<div>
    $$
        \begin{align*}
            \min_{\fv \in \Rbb^{|\Vcal|}} ~ \fv^\top \Lv \fv \quad \st ~ (D \fv)^\top \ev = 0, ~ \fv^\top \Dv \fv = \vol(\Vcal)
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">二分 归一化割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

将问题放松为

<div>
    $$
        \begin{align*}
            \min_{\fv \in \Rbb^{|\Vcal|}} ~ \fv^\top \Lv \fv \quad \st ~ (D \fv)^\top \ev = 0, ~ \fv^\top \Dv \fv = \vol(\Vcal)
        \end{align*}
    $$
</div>

</br>

记$\gv = \Dv^{1/2} \fv$，问题可进一步写为

<div>
    $$
        \begin{align*}
            \min_{\fv \in \Rbb^{|\Vcal|}} ~ \gv^\top \Dv^{-1/2} \Lv \Dv^{-1/2} \gv \quad \st ~ \gv^\top \Dv^{1/2} \ev = 0, ~ \gv^\top \gv = \vol(\Vcal)
        \end{align*}
    $$
</div>

</br>

注意$\Dv^{-1/2} \Lv \Dv^{-1/2} = \Lv_{\text{sym}}$，$\Dv^{1/2} \ev$是其最小的特征向量，因此最优解$\gv^\star$是其倒数第二小的特征向量

</br>

进一步$\fv^\star = \Dv^{-1/2} \gv^\star$是$\Lv_{\text{rm}}$倒数第二小的特征向量

</br>

对$\fv^\star$做聚类反推划分就是$K=2$的归一化谱聚类

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

设$K > 2$，则优化问题为$\min_{\Vcal_1, \ldots, \Vcal_K} ~ \ncut (\Vcal_1, \ldots, \Vcal_K)$

定义$K$个指示向量$\hv_k \in \Rbb^{|\Vcal|}$

<div>
    $$
        \begin{align*}
            [\hv_k]_v = \begin{cases}
                1 / \sqrt{\vol(\Vcal_k)} & 若~v \in \Vcal_k \\
                0 & 若~v \not \in \Vcal_k
            \end{cases}
        \end{align*}
    $$
</div>

易知

<div>
    $$
        \begin{align*}
            \hv_k^\top \Lv \hv_k & = \frac{1}{2} \sum_{(u,v) \in \Ecal} ([\hv_k]_u - [\hv_k]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Vcal_k, v \not \in \Vcal_k} ([\hv_k]_u - [\hv_k]_v)^2 + \frac{1}{2} \sum_{u \not \in \Vcal_k, v \in \Vcal_k} ([\hv_k]_u - [\hv_k]_v)^2 \\
            & = \frac{1}{2} \sum_{u \in \Vcal_k, v \not \in \Vcal_k} \frac{1}{\vol(\Vcal_k)} + \frac{1}{2} \sum_{u \not \in \Vcal_k, v \in \Vcal_k} \frac{1}{\vol(\Vcal_k)} = \frac{\cut (\Vcal_k, \overline{\Vcal}_k)}{\vol(\Vcal_k)}
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 归一化割</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

于是

<div>
    $$
        \begin{align*}
            \ncut (\Vcal_1, \ldots, \Vcal_K) & = \sum_{k \in [K]} \frac{\cut(\Vcal_k, \overline{\Vcal_k})}{\vol(\Vcal_k)} = \sum_{k \in [K]} \hv_k^\top \Lv \hv_k \\
            & = \sum_{k \in [K]} [\Hv^\top \Lv \Hv]_{kk} = \tr (\Hv^\top \Lv \Hv)
        \end{align*}
    $$
</div>

其中$\Hv = [\hv_1, \ldots, \hv_K]$，且有$\hv_k \Dv \hv_k = \sum_{v \in \Vcal} d_v / \vol(\Vcal_k) = 1$，写成矩阵的形式$\Hv^\top \Dv \Hv = \Iv$

</br>

综上优化问题为

<div>
    $$
        \begin{align*}
            \min_{\Vcal_1, \ldots, \Vcal_K} ~ \tr (\Hv^\top \Lv \Hv) \quad \st & ~ [\hv_k]_v = \begin{cases}
                1 / \sqrt{\vol(\Vcal_k)} & 若~v \in \Vcal_k \\
                0 & 若~v \not \in \Vcal_k
            \end{cases} \\
            & ~ \Hv^\top \Dv \Hv = \Iv
        \end{align*}
    $$
</div>

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>

<!-- slide vertical=true data-notes="" -->
<div class="multi_column">
    <div class="title_hr"> 
        <hr class="hr_top">
        <h5 class="title">多分 归一化割 求解</h5>
    </div>
    <img class="xiaohui" src="../common/img/xiaohui.png" height=120px>
</div>

去掉离散约束，问题放松为

<div>
    $$
        \begin{align*}
            \min_{\Hv \in \Rbb^{|\Vcal| \times K}} ~ \tr (\Hv^\top \Lv \Hv) \quad \st ~ \Hv^\top \Dv \Hv = \Iv
        \end{align*}
    $$
</div>

</br>

记$\Tv = \Dv^{1/2} \Hv$，问题可进一步写为

<div>
    $$
        \begin{align*}
            \min_{\Tv \in \Rbb^{|\Vcal| \times K}} ~ \Tv^\top \underbrace{\Dv^{-1/2} \Lv \Dv^{-1/2}}_{\Lv_{\text{sym}}} \Tv \quad \st ~ \Tv^\top \Tv = \Iv
        \end{align*}
    $$
</div>

最优解$\Tv^\star$是$\Lv_{\text{sym}}$最小$K$个特征值对应的特征向量，进一步原问题最优解$\Hv^\star = \Dv^{-1/2} \Tv^\star$是$\Lv_{\text{rm}}$最小$K$个特征值对应的特征向量

</br>

同样将$K$个特征向量聚成$K$簇可以反推出划分，就是一般形式的归一化谱聚类

<div class="footer">
    <hr class="hr_bottom">
    <div class="multi_column">
        <h6 class="bottom_left">图神经网络导论</h6>
        <h6 class="bottom_center">谱图理论</h6>
        <h6 class="bottom_right">tengzhang@hust.edu.cn</h6>
    </div>
</div>
